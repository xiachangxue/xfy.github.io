
@Article{rs16071183,
AUTHOR = {Zhu, Xianhong and Huang, Xiaohui and Cao, Weijia and Yang, Xiaofei and Zhou, Yunfei and Wang, Shaokai},
TITLE = {Road Extraction from Remote Sensing Imagery with Spatial Attention Based on Swin Transformer},
JOURNAL = {Remote Sensing},
VOLUME = {16},
YEAR = {2024},
NUMBER = {7},
ARTICLE-NUMBER = {1183},
URL = {https://www.mdpi.com/2072-4292/16/7/1183},
ISSN = {2072-4292},
ABSTRACT = {Road extraction is a crucial aspect of remote sensing imagery processing that plays a significant role in various remote sensing applications, including automatic driving, urban planning, and path navigation. However, accurate road extraction is a challenging task due to factors such as high road density, building occlusion, and complex traffic environments. In this study, a Spatial Attention Swin Transformer (SASwin Transformer) architecture is proposed to create a robust encoder capable of extracting roads from remote sensing imagery. In this architecture, we have developed a spatial self-attention (SSA) module that captures efficient and rich spatial information through spatial self-attention to reconstruct the feature map. Following this, the module performs residual connections with the input, which helps reduce interference from unrelated regions. Additionally, we designed a Spatial MLP (SMLP) module to aggregate spatial feature information from multiple branches while simultaneously reducing computational complexity. Two public road datasets, the Massachusetts dataset and the DeepGlobe dataset, were used for extensive experiments. The results show that our proposed model has an improved overall performance compared to several state-of-the-art algorithms. In particular, on the two datasets, our model outperforms D-LinkNet with an increase in Intersection over Union (IoU) metrics of 1.88% and 1.84%, respectively.},
DOI = {10.3390/rs16071183}
}



